import os
import logging
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, CallbackQueryHandler, ContextTypes, filters
import numpy as np
from pydub import AudioSegment
from pydub.effects import normalize, compress_dynamic_range
import matplotlib.pyplot as plt
import io

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

# –¢–æ–∫–µ–Ω –±–æ—Ç–∞ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
BOT_TOKEN = os.getenv('BOT_TOKEN', 'YOUR_BOT_TOKEN_HERE')

# –•—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
user_data = {}

class AudioProcessor:
    @staticmethod
    def analyze_audio(audio_segment):
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –∞—É–¥–∏–æ"""
        samples = np.array(audio_segment.get_array_of_samples())
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ –¥–∏–∞–ø–∞–∑–æ–Ω—É -1 –¥–æ 1
        if audio_segment.sample_width == 2:
            samples = samples / 32768.0
        
        # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        rms = np.sqrt(np.mean(samples**2))
        peak = np.max(np.abs(samples))
        dynamic_range = 20 * np.log10(peak / (rms + 0.0001))
        quality = min(100, max(0, (dynamic_range / 60) * 100))
        
        return {
            'channels': audio_segment.channels,
            'sample_rate': audio_segment.frame_rate,
            'duration': len(audio_segment) / 1000.0,
            'rms': rms,
            'peak': peak,
            'dynamic_range': dynamic_range,
            'quality': round(quality, 1),
            'is_mono': audio_segment.channels == 1
        }
    
    @staticmethod
    def check_enhanced_tag(file_path):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, –±—ã–ª –ª–∏ —Ñ–∞–π–ª —É–∂–µ —É–ª—É—á—à–µ–Ω"""
        try:
            audio = AudioSegment.from_file(file_path)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–≥ –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
            return '[ENHANCED]' in os.path.basename(file_path)
        except:
            return False
    
    @staticmethod
    def enhance_audio(audio_segment):
        """–£–ª—É—á—à–µ–Ω–∏–µ –∞—É–¥–∏–æ"""
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        enhanced = normalize(audio_segment)
        
        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –∫–æ–º–ø—Ä–µ—Å—Å–∏—è
        enhanced = compress_dynamic_range(enhanced, threshold=-20.0, ratio=4.0, attack=5.0, release=50.0)
        
        # –ù–µ–±–æ–ª—å—à–æ–µ —É—Å–∏–ª–µ–Ω–∏–µ
        enhanced = enhanced + 3  # +3 dB
        
        return enhanced
    
    @staticmethod
    def mono_to_stereo(audio_segment):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –º–æ–Ω–æ –≤ —Å—Ç–µ—Ä–µ–æ"""
        if audio_segment.channels == 1:
            return AudioSegment.from_mono_audiosegments(audio_segment, audio_segment)
        return audio_segment
    
    @staticmethod
    def create_comparison_chart(before_stats, after_stats):
        """–°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        metrics = ['–ö–∞—á–µ—Å—Ç–≤–æ\n(%)', 'RMS\n(x100)', '–î–∏–Ω–∞–º–∏–∫–∞\n(dB)']
        before_values = [before_stats['quality'], before_stats['rms'] * 100, before_stats['dynamic_range']]
        after_values = [after_stats['quality'], after_stats['rms'] * 100, after_stats['dynamic_range']]
        
        x = np.arange(len(metrics))
        width = 0.35
        
        fig, ax = plt.subplots(figsize=(10, 6))
        bars1 = ax.bar(x - width/2, before_values, width, label='–î–æ —É–ª—É—á—à–µ–Ω–∏—è', color='#ef4444')
        bars2 = ax.bar(x + width/2, after_values, width, label='–ü–æ—Å–ª–µ —É–ª—É—á—à–µ–Ω–∏—è', color='#10b981')
        
        ax.set_ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ', fontsize=12)
        ax.set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∞—É–¥–∏–æ', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(metrics)
        ax.legend()
        ax.grid(axis='y', alpha=0.3)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞–¥ —Å—Ç–æ–ª–±—Ü–∞–º–∏
        for bars in [bars1, bars2]:
            for bar in bars:
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height,
                       f'{height:.1f}',
                       ha='center', va='bottom', fontsize=10)
        
        plt.tight_layout()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±—É—Ñ–µ—Ä
        buf = io.BytesIO()
        plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')
        buf.seek(0)
        plt.close()
        
        return buf

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ö–æ–º–∞–Ω–¥–∞ /start"""
    keyboard = [
        [InlineKeyboardButton("üìä –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞", callback_data='analyze')],
        [InlineKeyboardButton("‚ú® –£–ª—É—á—à–∏—Ç—å –∑–≤—É–∫", callback_data='enhance')],
        [InlineKeyboardButton("üéµ –ú–æ–Ω–æ ‚Üí –°—Ç–µ—Ä–µ–æ", callback_data='mono_to_stereo')],
        [InlineKeyboardButton("üöÄ –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞", callback_data='full_process')],
        [InlineKeyboardButton("‚ÑπÔ∏è –ü–æ–º–æ—â—å", callback_data='help')]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    welcome_text = (
        "üéµ *–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ –ê—É–¥–∏–æ –£–ª—É—á—à–∞—Ç–µ–ª—å!*\n\n"
        "–Ø –ø–æ–º–æ–≥—É —É–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –≤–∞—à–∏—Ö –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤.\n\n"
        "–ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ –∞—É–¥–∏–æ —Ñ–∞–π–ª –∏ –≤—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:"
    )
    
    await update.message.reply_text(welcome_text, reply_markup=reply_markup, parse_mode='Markdown')

async def button_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–∂–∞—Ç–∏–π –Ω–∞ –∫–Ω–æ–ø–∫–∏"""
    query = update.callback_query
    await query.answer()
    
    user_id = query.from_user.id
    action = query.data
    
    if action == 'help':
        help_text = (
            "üìñ *–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:*\n\n"
            "1Ô∏è‚É£ –û—Ç–ø—Ä–∞–≤—å—Ç–µ –∞—É–¥–∏–æ —Ñ–∞–π–ª\n"
            "2Ô∏è‚É£ –í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:\n\n"
            "üìä *–ê–Ω–∞–ª–∏–∑* - –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∑–≤—É–∫–∞\n"
            "‚ú® *–£–ª—É—á—à–∏—Ç—å* - –∫–æ–º–ø—Ä–µ—Å—Å–∏—è –∏ —É—Å–∏–ª–µ–Ω–∏–µ\n"
            "üéµ *–ú–æ–Ω–æ‚Üí–°—Ç–µ—Ä–µ–æ* - –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∫–∞–Ω–∞–ª–æ–≤\n"
            "üöÄ *–ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞* - –≤—Å—ë —Å—Ä–∞–∑—É\n\n"
            "–§–∞–π–ª—ã —Å –º–µ—Ç–∫–æ–π [ENHANCED] –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –ø–æ–≤—Ç–æ—Ä–Ω–æ.\n"
            "–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ FLAC."
        )
        await query.edit_message_text(help_text, parse_mode='Markdown')
        return
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—ã–±—Ä–∞–Ω–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ
    if user_id not in user_data:
        user_data[user_id] = {}
    
    user_data[user_id]['action'] = action
    
    action_names = {
        'analyze': 'üìä –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞',
        'enhance': '‚ú® –£–ª—É—á—à–µ–Ω–∏–µ –∑–≤—É–∫–∞',
        'mono_to_stereo': 'üéµ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å—Ç–µ—Ä–µ–æ',
        'full_process': 'üöÄ –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞'
    }
    
    await query.edit_message_text(
        f"–í—ã–±—Ä–∞–Ω–æ: *{action_names.get(action, action)}*\n\n"
        f"–¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∞—É–¥–∏–æ —Ñ–∞–π–ª –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.",
        parse_mode='Markdown'
    )

async def handle_audio(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤"""
    user_id = update.message.from_user.id
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤—ã–±—Ä–∞–Ω–æ –ª–∏ –¥–µ–π—Å—Ç–≤–∏–µ
    if user_id not in user_data or 'action' not in user_data[user_id]:
        keyboard = [
            [InlineKeyboardButton("üìä –ê–Ω–∞–ª–∏–∑", callback_data='analyze'),
             InlineKeyboardButton("‚ú® –£–ª—É—á—à–∏—Ç—å", callback_data='enhance')],
            [InlineKeyboardButton("üéµ –ú–æ–Ω–æ‚Üí–°—Ç–µ—Ä–µ–æ", callback_data='mono_to_stereo'),
             InlineKeyboardButton("üöÄ –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞", callback_data='full_process')]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        await update.message.reply_text(
            "–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ —Å –∞—É–¥–∏–æ:",
            reply_markup=reply_markup
        )
        return
    
    action = user_data[user_id]['action']
    
    # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª
    if update.message.audio:
        file = await update.message.audio.get_file()
        file_name = update.message.audio.file_name or 'audio.mp3'
    elif update.message.voice:
        file = await update.message.voice.get_file()
        file_name = 'voice.ogg'
    elif update.message.document:
        file = await update.message.document.get_file()
        file_name = update.message.document.file_name
    else:
        await update.message.reply_text("‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞")
        return
    
    await update.message.reply_text("‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Ñ–∞–π–ª...")
    
    try:
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
        input_path = f'temp_{user_id}_input'
        await file.download_to_drive(input_path)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Ç–∫—É
        if AudioProcessor.check_enhanced_tag(input_path):
            await update.message.reply_text("‚ö†Ô∏è –≠—Ç–æ—Ç —Ñ–∞–π–ª —É–∂–µ –±—ã–ª —É–ª—É—á—à–µ–Ω —Ä–∞–Ω–µ–µ!")
            os.remove(input_path)
            return
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ
        audio = AudioSegment.from_file(input_path)
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—ã–±—Ä–∞–Ω–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ
        if action == 'analyze':
            stats = AudioProcessor.analyze_audio(audio)
            
            analysis_text = (
                f"üìä *–ê–Ω–∞–ª–∏–∑ –∞—É–¥–∏–æ:*\n\n"
                f"üéµ –ö–∞–Ω–∞–ª—ã: {'–ú–æ–Ω–æ' if stats['is_mono'] else '–°—Ç–µ—Ä–µ–æ'}\n"
                f"üì° –ß–∞—Å—Ç–æ—Ç–∞: {stats['sample_rate']} Hz\n"
                f"‚è± –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {stats['duration']:.1f} —Å–µ–∫\n"
                f"üìà –ö–∞—á–µ—Å—Ç–≤–æ: {stats['quality']}%\n"
                f"üìä RMS: {stats['rms']:.3f}\n"
                f"üîä Peak: {stats['peak']:.3f}\n"
                f"üéö –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω: {stats['dynamic_range']:.1f} dB"
            )
            
            await update.message.reply_text(analysis_text, parse_mode='Markdown')
        
        elif action == 'mono_to_stereo':
            if audio.channels == 1:
                audio = AudioProcessor.mono_to_stereo(audio)
                output_path = f'temp_{user_id}_output.flac'
                audio.export(output_path, format='flac')
                
                await update.message.reply_audio(
                    audio=open(output_path, 'rb'),
                    filename=file_name.replace('.', '_stereo.') if '.' in file_name else file_name + '_stereo.flac',
                    caption="‚úÖ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –≤ —Å—Ç–µ—Ä–µ–æ"
                )
                os.remove(output_path)
            else:
                await update.message.reply_text("‚ÑπÔ∏è –§–∞–π–ª —É–∂–µ –≤ —Å—Ç–µ—Ä–µ–æ —Ñ–æ—Ä–º–∞—Ç–µ")
        
        elif action == 'enhance':
            before_stats = AudioProcessor.analyze_audio(audio)
            enhanced = AudioProcessor.enhance_audio(audio)
            after_stats = AudioProcessor.analyze_audio(enhanced)
            
            output_path = f'temp_{user_id}_output.flac'
            base_name = file_name.rsplit('.', 1)[0] if '.' in file_name else file_name
            output_name = f"{base_name}[ENHANCED].flac"
            
            enhanced.export(output_path, format='flac')
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≥—Ä–∞—Ñ–∏–∫
            chart = AudioProcessor.create_comparison_chart(before_stats, after_stats)
            await update.message.reply_photo(photo=chart, caption="üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞")
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∞–π–ª
            await update.message.reply_audio(
                audio=open(output_path, 'rb'),
                filename=output_name,
                caption=(
                    f"‚úÖ *–ê—É–¥–∏–æ —É–ª—É—á—à–µ–Ω–æ!*\n\n"
                    f"–ö–∞—á–µ—Å—Ç–≤–æ: {before_stats['quality']}% ‚Üí {after_stats['quality']}%"
                ),
                parse_mode='Markdown'
            )
            os.remove(output_path)
        
        elif action == 'full_process':
            await update.message.reply_text("üöÄ –í—ã–ø–æ–ª–Ω—è—é –ø–æ–ª–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É...")
            
            # –ê–Ω–∞–ª–∏–∑ –¥–æ
            before_stats = AudioProcessor.analyze_audio(audio)
            
            # –ú–æ–Ω–æ ‚Üí –°—Ç–µ—Ä–µ–æ
            if audio.channels == 1:
                audio = AudioProcessor.mono_to_stereo(audio)
                await update.message.reply_text("‚úì –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –≤ —Å—Ç–µ—Ä–µ–æ")
            
            # –£–ª—É—á—à–µ–Ω–∏–µ
            enhanced = AudioProcessor.enhance_audio(audio)
            await update.message.reply_text("‚úì –ó–≤—É–∫ —É–ª—É—á—à–µ–Ω")
            
            # –ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ
            after_stats = AudioProcessor.analyze_audio(enhanced)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            output_path = f'temp_{user_id}_output.flac'
            base_name = file_name.rsplit('.', 1)[0] if '.' in file_name else file_name
            output_name = f"{base_name}[ENHANCED].flac"
            
            enhanced.export(output_path, format='flac', bitrate='320k')
            
            # –ì—Ä–∞—Ñ–∏–∫
            chart = AudioProcessor.create_comparison_chart(before_stats, after_stats)
            await update.message.reply_photo(
                photo=chart,
                caption="üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏"
            )
            
            # –ò—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª
            await update.message.reply_audio(
                audio=open(output_path, 'rb'),
                filename=output_name,
                caption=(
                    f"‚úÖ *–ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!*\n\n"
                    f"üìä –ö–∞—á–µ—Å—Ç–≤–æ: {before_stats['quality']}% ‚Üí {after_stats['quality']}%\n"
                    f"üéµ –ö–∞–Ω–∞–ª—ã: {'–ú–æ–Ω–æ' if before_stats['is_mono'] else '–°—Ç–µ—Ä–µ–æ'} ‚Üí –°—Ç–µ—Ä–µ–æ\n"
                    f"üíæ –§–æ—Ä–º–∞—Ç: FLAC"
                ),
                parse_mode='Markdown'
            )
            os.remove(output_path)
        
        # –û—á–∏—Å—Ç–∫–∞
        os.remove(input_path)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –º–µ–Ω—é —Å–Ω–æ–≤–∞
        keyboard = [
            [InlineKeyboardButton("üìä –ê–Ω–∞–ª–∏–∑", callback_data='analyze'),
             InlineKeyboardButton("‚ú® –£–ª—É—á—à–∏—Ç—å", callback_data='enhance')],
            [InlineKeyboardButton("üéµ –ú–æ–Ω–æ‚Üí–°—Ç–µ—Ä–µ–æ", callback_data='mono_to_stereo'),
             InlineKeyboardButton("üöÄ –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞", callback_data='full_process')]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        await update.message.reply_text(
            "–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –µ—â—ë –æ–¥–∏–Ω —Ñ–∞–π–ª?",
            reply_markup=reply_markup
        )
        
    except Exception as e:
        logger.error(f"Error processing audio: {e}")
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}")
        if os.path.exists(input_path):
            os.remove(input_path)

def main():
    """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞"""
    app = Application.builder().token(BOT_TOKEN).build()
    
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CallbackQueryHandler(button_callback))
    app.add_handler(MessageHandler(filters.AUDIO | filters.VOICE | filters.Document.AUDIO, handle_audio))
    
    logger.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω!")
    app.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == '__main__':
    main()
