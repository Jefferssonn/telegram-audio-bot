import os
import logging
import tempfile
import asyncio
from typing import Dict, Optional, Any
from datetime import datetime, timedelta
from contextlib import asynccontextmanager
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, CallbackQueryHandler, ContextTypes, filters
import numpy as np
from pydub import AudioSegment
from pydub.effects import normalize, compress_dynamic_range
import matplotlib.pyplot as plt
import io

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', 
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# –¢–æ–∫–µ–Ω –±–æ—Ç–∞ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
BOT_TOKEN = os.getenv('BOT_TOKEN', 'YOUR_BOT_TOKEN_HERE')

class UserSessionManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä —Å–µ—Å—Å–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å TTL"""
    
    def __init__(self, ttl_minutes: int = 30):
        self.sessions: Dict[int, Dict[str, Any]] = {}
        self.ttl_seconds = ttl_minutes * 60
        
    def get_session(self, user_id: int) -> Optional[Dict[str, Any]]:
        if user_id in self.sessions:
            session = self.sessions[user_id]
            if datetime.now() < session.get('expires_at', datetime.min):
                return session
            else:
                del self.sessions[user_id]
        return None
    
    def create_session(self, user_id: int, action: str) -> Dict[str, Any]:
        session = {
            'action': action,
            'created_at': datetime.now(),
            'expires_at': datetime.now() + timedelta(seconds=self.ttl_seconds)
        }
        self.sessions[user_id] = session
        return session
    
    def clear_expired(self):
        now = datetime.now()
        expired_users = [
            user_id for user_id, session in self.sessions.items()
            if now >= session.get('expires_at', now)
        ]
        for user_id in expired_users:
            del self.sessions[user_id]

class AudioProcessor:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤"""
    
    MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB –≤ –±–∞–π—Ç–∞—Ö
    
    @staticmethod
    def analyze_audio(audio_segment: AudioSegment) -> Dict[str, float]:
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –∞—É–¥–∏–æ"""
        samples = np.array(audio_segment.get_array_of_samples())
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ –¥–∏–∞–ø–∞–∑–æ–Ω—É -1 –¥–æ 1
        if audio_segment.sample_width == 2:
            samples = samples / 32768.0
        
        # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        rms = np.sqrt(np.mean(samples**2))
        peak = np.max(np.abs(samples))
        dynamic_range = 20 * np.log10(peak / (rms + 0.0001))
        quality = min(100, max(0, (dynamic_range / 60) * 100))
        
        return {
            'channels': audio_segment.channels,
            'sample_rate': audio_segment.frame_rate,
            'duration': len(audio_segment) / 1000.0,
            'rms': rms,
            'peak': peak,
            'dynamic_range': dynamic_range,
            'quality': round(quality, 1),
            'is_mono': audio_segment.channels == 1
        }
    
    @staticmethod
    def check_enhanced_tag(file_path: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, –±—ã–ª –ª–∏ —Ñ–∞–π–ª —É–∂–µ —É–ª—É—á—à–µ–Ω"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–≥ –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            return '[ENHANCED]' in os.path.basename(file_path)
        except:
            return False
    
    @staticmethod
    def enhance_audio(audio_segment: AudioSegment) -> AudioSegment:
        """–£–ª—É—á—à–µ–Ω–∏–µ –∞—É–¥–∏–æ"""
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        enhanced = normalize(audio_segment)
        
        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –∫–æ–º–ø—Ä–µ—Å—Å–∏—è
        enhanced = compress_dynamic_range(enhanced, threshold=-20.0, ratio=4.0, attack=5.0, release=50.0)
        
        # –ù–µ–±–æ–ª—å—à–æ–µ —É—Å–∏–ª–µ–Ω–∏–µ
        enhanced = enhanced + 3  # +3 dB
        
        return enhanced
    
    @staticmethod
    def mono_to_stereo(audio_segment: AudioSegment) -> AudioSegment:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –º–æ–Ω–æ –≤ —Å—Ç–µ—Ä–µ–æ"""
        if audio_segment.channels == 1:
            return AudioSegment.from_mono_audiosegments(audio_segment, audio_segment)
        return audio_segment
    
    @staticmethod
    def create_comparison_chart(before_stats: Dict[str, float], after_stats: Dict[str, float]) -> io.BytesIO:
        """–°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        metrics = ['–ö–∞—á–µ—Å—Ç–≤–æ\n(%)', 'RMS\n(x100)', '–î–∏–Ω–∞–º–∏–∫–∞\n(dB)']
        before_values = [before_stats['quality'], before_stats['rms'] * 100, before_stats['dynamic_range']]
        after_values = [after_stats['quality'], after_stats['rms'] * 100, after_stats['dynamic_range']]
        
        x = np.arange(len(metrics))
        width = 0.35
        
        fig, ax = plt.subplots(figsize=(10, 6))
        bars1 = ax.bar(x - width/2, before_values, width, label='–î–æ —É–ª—É—á—à–µ–Ω–∏—è', color='#ef4444')
        bars2 = ax.bar(x + width/2, after_values, width, label='–ü–æ—Å–ª–µ —É–ª—É—á—à–µ–Ω–∏—è', color='#10b981')
        
        ax.set_ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ', fontsize=12)
        ax.set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∞—É–¥–∏–æ', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(metrics)
        ax.legend()
        ax.grid(axis='y', alpha=0.3)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞–¥ —Å—Ç–æ–ª–±—Ü–∞–º–∏
        for bars in [bars1, bars2]:
            for bar in bars:
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height,
                       f'{height:.1f}',
                       ha='center', va='bottom', fontsize=10)
        
        plt.tight_layout()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±—É—Ñ–µ—Ä
        buf = io.BytesIO()
        plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')
        buf.seek(0)
        plt.close()
        
        return buf

class AudioBot:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –±–æ—Ç–∞"""
    
    def __init__(self):
        self.session_manager = UserSessionManager()
        self.audio_processor = AudioProcessor()
        
    async def start(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–ö–æ–º–∞–Ω–¥–∞ /start"""
        keyboard = [
            [InlineKeyboardButton("üìä –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞", callback_data='analyze')],
            [InlineKeyboardButton("‚ú® –£–ª—É—á—à–∏—Ç—å –∑–≤—É–∫", callback_data='enhance')],
            [InlineKeyboardButton("üéµ –ú–æ–Ω–æ ‚Üí –°—Ç–µ—Ä–µ–æ", callback_data='mono_to_stereo')],
            [InlineKeyboardButton("üöÄ –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞", callback_data='full_process')],
            [InlineKeyboardButton("‚ÑπÔ∏è –ü–æ–º–æ—â—å", callback_data='help')]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        welcome_text = (
            "üéµ *–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ –ê—É–¥–∏–æ –£–ª—É—á—à–∞—Ç–µ–ª—å!*\n\n"
            "–Ø –ø–æ–º–æ–≥—É —É–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –≤–∞—à–∏—Ö –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤.\n\n"
            "–ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ –∞—É–¥–∏–æ —Ñ–∞–π–ª –∏ –≤—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:"
        )
        
        await update.message.reply_text(welcome_text, reply_markup=reply_markup, parse_mode='Markdown')

    async def button_callback(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–∂–∞—Ç–∏–π –Ω–∞ –∫–Ω–æ–ø–∫–∏"""
        query = update.callback_query
        await query.answer()
        
        user_id = query.from_user.id
        action = query.data
        
        if action == 'help':
            help_text = (
                "üìñ *–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:*\n\n"
                "1Ô∏è‚É£ –û—Ç–ø—Ä–∞–≤—å—Ç–µ –∞—É–¥–∏–æ —Ñ–∞–π–ª\n"
                "2Ô∏è‚É£ –í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:\n\n"
                "üìä *–ê–Ω–∞–ª–∏–∑* - –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∑–≤—É–∫–∞\n"
                "‚ú® *–£–ª—É—á—à–∏—Ç—å* - –∫–æ–º–ø—Ä–µ—Å—Å–∏—è –∏ —É—Å–∏–ª–µ–Ω–∏–µ\n"
                "üéµ *–ú–æ–Ω–æ‚Üí–°—Ç–µ—Ä–µ–æ* - –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∫–∞–Ω–∞–ª–æ–≤\n"
                "üöÄ *–ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞* - –≤—Å—ë —Å—Ä–∞–∑—É\n\n"
                "–§–∞–π–ª—ã —Å –º–µ—Ç–∫–æ–π [ENHANCED] –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –ø–æ–≤—Ç–æ—Ä–Ω–æ.\n"
                "–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ FLAC."
            )
            await query.edit_message_text(help_text, parse_mode='Markdown')
            return
        
        # –°–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏—é –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        self.session_manager.create_session(user_id, action)
        
        action_names = {
            'analyze': 'üìä –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞',
            'enhance': '‚ú® –£–ª—É—á—à–µ–Ω–∏–µ –∑–≤—É–∫–∞',
            'mono_to_stereo': 'üéµ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å—Ç–µ—Ä–µ–æ',
            'full_process': 'üöÄ –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞'
        }
        
        await query.edit_message_text(
            f"–í—ã–±—Ä–∞–Ω–æ: *{action_names.get(action, action)}*\n\n"
            f"–¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∞—É–¥–∏–æ —Ñ–∞–π–ª –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.",
            parse_mode='Markdown'
        )

    async def handle_audio(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤"""
        user_id = update.message.from_user.id
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∞–∫—Ç–∏–≤–Ω–∞—è —Å–µ—Å—Å–∏—è
        session = self.session_manager.get_session(user_id)
        if not session:
            await self.send_action_menu(update)
            return
        
        action = session['action']
        
        # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª
        if update.message.audio:
            file = await update.message.audio.get_file()
            file_name = update.message.audio.file_name or 'audio.mp3'
        elif update.message.voice:
            file = await update.message.voice.get_file()
            file_name = 'voice.ogg'
        elif update.message.document:
            file = await update.message.document.get_file()
            file_name = update.message.document.file_name
        else:
            await update.message.reply_text("‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞")
            return
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        if hasattr(file, 'file_size') and file.file_size > self.audio_processor.MAX_FILE_SIZE:
            await update.message.reply_text(f"‚ùå –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –ø—Ä–µ–≤—ã—à–∞–µ—Ç {self.audio_processor.MAX_FILE_SIZE // (1024*1024)} MB")
            return
        
        await update.message.reply_text("‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Ñ–∞–π–ª...")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        with tempfile.NamedTemporaryFile(delete=False) as temp_input:
            temp_input_path = temp_input.name
            
        try:
            # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
            await file.download_to_drive(temp_input_path)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Ç–∫—É
            if self.audio_processor.check_enhanced_tag(temp_input_path):
                await update.message.reply_text("‚ö†Ô∏è –≠—Ç–æ—Ç —Ñ–∞–π–ª —É–∂–µ –±—ã–ª —É–ª—É—á—à–µ–Ω —Ä–∞–Ω–µ–µ!")
                return
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ
            audio = AudioSegment.from_file(temp_input_path)
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—ã–±—Ä–∞–Ω–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ
            await self._execute_action(update, action, audio, file_name)
            
        except Exception as e:
            logger.error(f"Error processing audio: {e}")
            await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}")
        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            if os.path.exists(temp_input_path):
                os.unlink(temp_input_path)
            
            # –£–¥–∞–ª—è–µ–º —Å–µ—Å—Å–∏—é
            if user_id in self.session_manager.sessions:
                del self.session_manager.sessions[user_id]
    
    async def _execute_action(self, update: Update, action: str, audio: AudioSegment, file_name: str):
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è"""
        user_id = update.message.from_user.id
        
        if action == 'analyze':
            stats = self.audio_processor.analyze_audio(audio)
            
            analysis_text = (
                f"üìä *–ê–Ω–∞–ª–∏–∑ –∞—É–¥–∏–æ:*\n\n"
                f"üéµ –ö–∞–Ω–∞–ª—ã: {'–ú–æ–Ω–æ' if stats['is_mono'] else '–°—Ç–µ—Ä–µ–æ'}\n"
                f"üì° –ß–∞—Å—Ç–æ—Ç–∞: {stats['sample_rate']} Hz\n"
                f"‚è± –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {stats['duration']:.1f} —Å–µ–∫\n"
                f"üìà –ö–∞—á–µ—Å—Ç–≤–æ: {stats['quality']}%\n"
                f"üìä RMS: {stats['rms']:.3f}\n"
                f"üîä Peak: {stats['peak']:.3f}\n"
                f"üéö –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω: {stats['dynamic_range']:.1f} dB"
            )
            
            await update.message.reply_text(analysis_text, parse_mode='Markdown')
        
        elif action == 'mono_to_stereo':
            if audio.channels == 1:
                processed_audio = self.audio_processor.mono_to_stereo(audio)
                
                with tempfile.NamedTemporaryFile(suffix='.flac', delete=False) as temp_output:
                    temp_output_path = temp_output.name
                
                try:
                    processed_audio.export(temp_output_path, format='flac')
                    
                    output_filename = file_name.replace('.', '_stereo.') if '.' in file_name else file_name + '_stereo.flac'
                    await update.message.reply_audio(
                        audio=open(temp_output_path, 'rb'),
                        filename=output_filename,
                        caption="‚úÖ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –≤ —Å—Ç–µ—Ä–µ–æ"
                    )
                finally:
                    if os.path.exists(temp_output_path):
                        os.unlink(temp_output_path)
            else:
                await update.message.reply_text("‚ÑπÔ∏è –§–∞–π–ª —É–∂–µ –≤ —Å—Ç–µ—Ä–µ–æ —Ñ–æ—Ä–º–∞—Ç–µ")
        
        elif action == 'enhance':
            before_stats = self.audio_processor.analyze_audio(audio)
            processed_audio = self.audio_processor.enhance_audio(audio)
            after_stats = self.audio_processor.analyze_audio(processed_audio)
            
            with tempfile.NamedTemporaryFile(suffix='.flac', delete=False) as temp_output:
                temp_output_path = temp_output.name
            
            try:
                base_name = file_name.rsplit('.', 1)[0] if '.' in file_name else file_name
                output_name = f"{base_name}[ENHANCED].flac"
                
                processed_audio.export(temp_output_path, format='flac')
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≥—Ä–∞—Ñ–∏–∫
                chart = self.audio_processor.create_comparison_chart(before_stats, after_stats)
                await update.message.reply_photo(photo=chart, caption="üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞")
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∞–π–ª
                await update.message.reply_audio(
                    audio=open(temp_output_path, 'rb'),
                    filename=output_name,
                    caption=(
                        f"‚úÖ *–ê—É–¥–∏–æ —É–ª—É—á—à–µ–Ω–æ!*\n\n"
                        f"–ö–∞—á–µ—Å—Ç–≤–æ: {before_stats['quality']}% ‚Üí {after_stats['quality']}%"
                    ),
                    parse_mode='Markdown'
                )
            finally:
                if os.path.exists(temp_output_path):
                    os.unlink(temp_output_path)
        
        elif action == 'full_process':
            await update.message.reply_text("üöÄ –í—ã–ø–æ–ª–Ω—è—é –ø–æ–ª–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É...")
            
            # –ê–Ω–∞–ª–∏–∑ –¥–æ
            before_stats = self.audio_processor.analyze_audio(audio)
            
            # –ú–æ–Ω–æ ‚Üí –°—Ç–µ—Ä–µ–æ
            if audio.channels == 1:
                audio = self.audio_processor.mono_to_stereo(audio)
                await update.message.reply_text("‚úì –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –≤ —Å—Ç–µ—Ä–µ–æ")

            # –£–ª—É—á—à–µ–Ω–∏–µ
            processed_audio = self.audio_processor.enhance_audio(audio)
            await update.message.reply_text("‚úì –ó–≤—É–∫ —É–ª—É—á—à–µ–Ω")
            
            # –ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ
            after_stats = self.audio_processor.analyze_audio(processed_audio)
            
            with tempfile.NamedTemporaryFile(suffix='.flac', delete=False) as temp_output:
                temp_output_path = temp_output.name
            
            try:
                base_name = file_name.rsplit('.', 1)[0] if '.' in file_name else file_name
                output_name = f"{base_name}[ENHANCED].flac"
                
                processed_audio.export(temp_output_path, format='flac', bitrate='320k')
                
                # –ì—Ä–∞—Ñ–∏–∫
                chart = self.audio_processor.create_comparison_chart(before_stats, after_stats)
                await update.message.reply_photo(
                    photo=chart,
                    caption="üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏"
                )
                
                # –ò—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª
                await update.message.reply_audio(
                    audio=open(temp_output_path, 'rb'),
                    filename=output_name,
                    caption=(
                        f"‚úÖ *–ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!*\n\n"
                        f"üìä –ö–∞—á–µ—Å—Ç–≤–æ: {before_stats['quality']}% ‚Üí {after_stats['quality']}%\n"
                        f"üéµ –ö–∞–Ω–∞–ª—ã: {'–ú–æ–Ω–æ' if before_stats['is_mono'] else '–°—Ç–µ—Ä–µ–æ'} ‚Üí –°—Ç–µ—Ä–µ–æ\n"
                        f"üíæ –§–æ—Ä–º–∞—Ç: FLAC"
                    ),
                    parse_mode='Markdown'
                )
            finally:
                if os.path.exists(temp_output_path):
                    os.unlink(temp_output_path)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –º–µ–Ω—é —Å–Ω–æ–≤–∞
        await self.send_action_menu(update)

    async def send_action_menu(self, update: Update):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –º–µ–Ω—é –≤—ã–±–æ—Ä–∞ –¥–µ–π—Å—Ç–≤–∏–π"""
        keyboard = [
            [InlineKeyboardButton("üìä –ê–Ω–∞–ª–∏–∑", callback_data='analyze'),
             InlineKeyboardButton("‚ú® –£–ª—É—á—à–∏—Ç—å", callback_data='enhance')],
            [InlineKeyboardButton("üéµ –ú–æ–Ω–æ‚Üí–°—Ç–µ—Ä–µ–æ", callback_data='mono_to_stereo'),
             InlineKeyboardButton("üöÄ –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞", callback_data='full_process')]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        await update.message.reply_text(
            "–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ —Å –∞—É–¥–∏–æ:",
            reply_markup=reply_markup
        )

def main():
    """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞"""
    bot = AudioBot()
    app = Application.builder().token(BOT_TOKEN).build()
    
    app.add_handler(CommandHandler("start", bot.start))
    app.add_handler(CallbackQueryHandler(bot.button_callback))
    app.add_handler(MessageHandler(filters.AUDIO | filters.VOICE | filters.Document.AUDIO, bot.handle_audio))
    
    logger.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω!")
    app.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == '__main__':
    main()